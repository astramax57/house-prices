{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit ('ml_common': conda)",
   "metadata": {
    "interpreter": {
     "hash": "62d83a1606262d6c61add99d30837c7ced3094adffc85cbd8650aea5b650e920"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import csv\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train contains data as is\n",
    "df_train = pd.read_csv('train.csv')\n",
    "\n",
    "target = df_train[['SalePrice']].copy()\n",
    "df_train_id = df_train[['Id']].copy()\n",
    "\n",
    "df_train = df_train.drop('SalePrice', axis=1)"
   ]
  },
  {
   "source": [
    "### Hyperparameters for coarse feature selecting\n",
    "\n",
    "* if feature has missing values more then `missing_values_ratio` - feature will be deleted \n",
    "* ~~if feature has mostly unique values more then `common_values_ratio` - feature will be deleted~~\n",
    "* if feature has more then `moda_0_ratio` - feature will be deleted"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_ratio = 0.5\n",
    "common_values_ratio = 0.9\n",
    "moda_0_ratio = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Columns which contain too many Missing Values\n",
    "df_train = df_train.loc[:,df_train.columns[df_train.isnull().mean() < missing_values_ratio]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove columns with mostly unique values\n",
    "#for column in df_train[cat_cols]:    \n",
    "#    if len(df_train[column].value_counts()) > common_values_ratio * df_train.shape[0]:\n",
    "#        df_train = df_train.drop(column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove colums with extremely scewed distributions\n",
    "for column in df_train.columns:    \n",
    "    if df_train[column].value_counts().values[0] > moda_0_ratio * df_train.shape[0]:\n",
    "        df_train = df_train.drop(column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#в колонках GarageX одинаковое количество пропущенных значений\n",
    "#при этом наиболее важная информация по гаражам содержится в колонке GarageCars\n",
    "#следовательно, остальные колонки GarageX можно удалить\n",
    "df_train = df_train.drop(['GarageType'], 1)\n",
    "df_train = df_train.drop(['GarageYrBlt'], 1)\n",
    "df_train = df_train.drop(['GarageFinish'], 1)\n",
    "df_train = df_train.drop(['GarageQual'], 1)\n",
    "df_train = df_train.drop(['GarageArea'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляю переменные, имеющие значительную корреляцию с аналогичными по смыслу переменными\n",
    "# переменные найдены на основе анализа тепловой карты, представленной ниже\n",
    "df_train = df_train.drop(['TotRmsAbvGrd'], 1)\n",
    "df_train = df_train.drop(['1stFlrSF'], 1)"
   ]
  },
  {
   "source": [
    "### Distinguish numerical from categorical columns\n",
    "* if feature has unique values less than `unique_value_number_for_numerical` - feature is categorical"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_value_number_for_numerical = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "categorical: ['MSSubClass', 'MSZoning', 'LotShape', 'LandContour', 'LotConfig', 'Neighborhood', 'Condition1', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'RoofStyle', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'BsmtFullBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenQual', 'Fireplaces', 'FireplaceQu', 'GarageCars', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition']\nnumerical: ['Id', 'LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '2ndFlrSF', 'GrLivArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch']\n"
     ]
    }
   ],
   "source": [
    "cat_cols = []\n",
    "num_cols = []\n",
    "for column in df_train.columns:\n",
    "    if df_train[column].nunique() < unique_value_number_for_numerical:\n",
    "        cat_cols.append(column)\n",
    "    else:\n",
    "        num_cols.append(column)\n",
    "\n",
    "print(f\"categorical: {cat_cols}\\nnumerical: {num_cols}\")"
   ]
  },
  {
   "source": [
    "privious automated approach to distinguish numerical and categorical features is not good.\n",
    "let's do it by hand"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['LotFrontage', 'LotArea', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1',\n",
    "    'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '2ndFlrSF', 'GrLivArea', 'WoodDeckSF', 'OpenPorchSF',\n",
    "    'EnclosedPorch', 'OverallQual', 'OverallCond', 'BsmtFullBath', 'FullBath', 'HalfBath',\n",
    "    'BedroomAbvGr','Fireplaces','GarageCars','MoSold', 'YrSold'\n",
    "]\n",
    "\n",
    "cat_cols = ['MSSubClass', 'MSZoning', 'LotShape', 'LandContour', 'LotConfig', 'Neighborhood', 'Condition1',\n",
    "    'BldgType', 'HouseStyle', 'RoofStyle', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond',\n",
    "    'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC',\n",
    "    'KitchenQual', 'FireplaceQu', 'SaleType', 'SaleCondition'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_final = df_train.columns\n",
    "cols_final_test = [c for c in cols_final if c not in ['SalePrice']]\n",
    "num_cols_test = [c for c in num_cols if c not in ['SalePrice']]"
   ]
  },
  {
   "source": [
    "### Correlation matrix\n",
    "тепловая карта. позволяет быстро оценить зависимость между переменными и выявить мультиколлинеарность (это плохо, модель не построить)\n",
    "белые квадраты указвывают на зависимость между переменными"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corrmat = df_train.corr()\n",
    "f, ax = plt.subplots(figsize=(12, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, square=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: somehow, the heatmap of my dataset doesn't show the null value sin the columns \n",
    "# 'country', 'province' and 'variety'. Please help me to fix this.\n",
    "def nullscan(df_check, save=False):\n",
    "    '''\n",
    "    df: a dataframe on which we want to perofrm the nullscan\n",
    "    save: determines, whether you want to save the .png of the plot or not\n",
    "    \n",
    "    plots the rate of null values per column in a dataframe using \n",
    "    a seaborn heatmap and a barplot.\n",
    "    '''    \n",
    "    # a df with the same size of the original dataframe, containing True in cells containing NUll values.\n",
    "    # and False in all the other cells.\n",
    "    df_nulls = df_check.isna()\n",
    "    # a series containing the sum of all values within a column having the column names as indices.\n",
    "    # True is interpreted as 1 and False is interpreted as 0 \n",
    "    nulls_per_col = df_nulls.sum(axis=0)\n",
    "    # the rate makes it way more interpretable:\n",
    "    nulls_per_col /= len(df_check.index)\n",
    "\n",
    "    with plt.style.context('dark_background'):\n",
    "        fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True, figsize=(8, 10))\n",
    "    \n",
    "        # ax1 is losely based on: https://www.kaggle.com/ipshitagh/wine-dataset-data-cleaning\n",
    "        # NOTE: I could have used the cmap viridis or anything else instead, \n",
    "        # but I want to make clear that you can use any customized cmap as well.\n",
    "        vir = matplotlib.cm.get_cmap('viridis')\n",
    "        colormap = matplotlib.colors.ListedColormap([vir(0), 'darkorange'])\n",
    "        sns.heatmap(df_check.isnull(), cmap=colormap, cbar=False, yticklabels=False, ax=ax1)\n",
    "    \n",
    "        nulls_per_col.plot(kind='bar', color='darkorange', x=nulls_per_col.values, \n",
    "                           y=nulls_per_col.index, ax=ax2, width=1, linewidth=1, \n",
    "                           edgecolor='black', align='edge', label='Null value rate')\n",
    "        \n",
    "        ax2.set_ylim((0,1))\n",
    "        # centered labels\n",
    "        labels=df_check.columns\n",
    "        ticks = np.arange(0.5, len(labels))\n",
    "        ax2.xaxis.set(ticks=ticks, ticklabels=labels)\n",
    "    \n",
    "        # hide spines:\n",
    "        # NOTE: I could have used ax2.set_frameon(False), \n",
    "        # but I wanted the bottom and the left spine to stay white.\n",
    "        ax2.spines['top'].set_color('black')\n",
    "        ax2.spines['right'].set_color('black')\n",
    "        \n",
    "        \n",
    "        \n",
    "        # workaround to visualize very small amounts of null values per col\n",
    "        #na_ticks = ticks[(nulls_per_col > 0) & (nulls_per_col < 0.05)]\n",
    "        #if (len(na_ticks) > 0):\n",
    "        #    ax2.plot(na_ticks, [0,]*len(na_ticks), 's', c='darkorange', markersize=10, \n",
    "        #             label='Very few missing values')\n",
    "    \n",
    "        fig.suptitle('Null Value Rate per Column', fontsize=30, y=1.05)\n",
    "        ax2.legend()\n",
    "        fig.tight_layout() \n",
    "        if(save):\n",
    "            plt.savefig('nullscan.png')\n",
    "        plt.show()\n",
    "nullscan(df_train, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')[cols_final_test]\n",
    "test_id = pd.read_csv('test.csv')['Id']\n",
    "\n",
    "train_and_test = pd.concat([df_train, test], axis=0)"
   ]
  },
  {
   "source": [
    "### Mean imputation\n",
    "* for categorical variables - replace missing values by the most common value\n",
    "* for numeric variables - replace by median value"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "for column in df_train.columns:\n",
    "    if column in cat_cols:\n",
    "        df_train[column] = df_train[column].fillna(value=train_and_test[column].value_counts().index[0])\n",
    "    else: \n",
    "        df_train[column] = df_train[column].fillna(value=train_and_test[column].median())\n",
    "\n",
    "# test \n",
    "for column in test.columns:\n",
    "    if column in cat_cols:\n",
    "        test[column] = test[column].fillna(value=train_and_test[column].value_counts().index[0])\n",
    "    else: \n",
    "        test[column] = test[column].fillna(value=train_and_test[column].median())"
   ]
  },
  {
   "source": [
    "### Numerical features scaling (not for features with log-transform)\n",
    "1. scaler fit on train_and_test\n",
    "2. scaler transform numerical values to (-1,1) range"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "log_transformation_col = ['GrLivArea', 'TotalBsmtSF', 'BsmtUnfSF', 'WoodDeckSF', 'TotalPorchSF', 'LotArea']\n",
    "\n",
    "col_for_scal = [col for col in num_cols_test if col not in log_transformation_col]\n",
    "\n",
    "for column in col_for_scal:    \n",
    "    scaler.fit(train_and_test[column].values.reshape(-1,1))\n",
    "    df_train[column] = scaler.transform(df_train[column].values.reshape(-1,1))\n",
    "    test[column] = scaler.transform(test[column].values.reshape(-1,1))"
   ]
  },
  {
   "source": [
    "### We need to encode categorical data\n",
    "1. first approach is to use OneHotEncoder"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(train_and_test[cat_cols])\n",
    "\n",
    "data_cat = enc.transform(df_train[cat_cols])\n",
    "data_cat.columns = enc.get_feature_names(cat_cols)\n",
    "  \n",
    "data_cat = pd.DataFrame.sparse.from_spmatrix(data_cat)\n",
    "data_cat.columns = enc.get_feature_names(cat_cols)\n",
    "df_train = df_train.drop(cat_cols, axis=1)\n",
    "df_train = pd.concat([df_train, data_cat], axis=1)\n",
    "#df_train.head()"
   ]
  },
  {
   "source": [
    "test_cat = test[cat_cols]\n",
    "test_cat = enc.transform(test[cat_cols])\n",
    "test_cat = pd.DataFrame(test_cat.todense())\n",
    "test_cat.columns = enc.get_feature_names(cat_cols)\n",
    "\n",
    "test = test.drop(cat_cols, axis=1)\n",
    "test = test.reset_index()\n",
    "test_cat = test_cat.reset_index()\n",
    "test = pd.concat([test, test_cat], axis=1)\n",
    "test = test.drop('index', axis=1)\n",
    "#test.head()"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "2. Second approach is to use hand encoding based"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSSubClass\n",
    "# 10 - low SalePrice median \n",
    "# 20 - medium SalePrice median \n",
    "# 30 - high SalePrice median \n",
    "mssubclass_category_codes = {\n",
    "    20: 30, 30: 10, 40: 20, 45: 10, 50: 30, 60: 30,\n",
    "    70: 20, 75: 20, 80: 20, 85: 10, 90: 10, 120: 20,\n",
    "    150: 20, 160: 20, 180: 10, 190: 20 \n",
    "}\n",
    " \n",
    "#MSZoning\n",
    "#only this codes in dataset: RL, RM, FV, RH, C (all)\n",
    "mszoning_codes = {'C (all)': 10, 'RM': 20, 'RH': 30, 'RL': 40, 'FV': 50}\n",
    "\n",
    "#Street\n",
    "street_codes = {'Grvl': 1, 'Pave': 2}\n",
    "\n",
    "#LotShape\n",
    "lotshape_codes = {'Reg': 10, 'IR1': 20, 'IR2': 30, 'IR3': 40}\n",
    "#LandContour\n",
    "landcontour_codes = {'Bnk': 10, 'Lvl': 20, 'Low': 30, 'HLS': 40}\n",
    "#Utilities\n",
    "utilities_codes = {'ELO': 1, 'NoSeWa': 2, 'NoSewr': 3, 'AllPub': 4}\n",
    "#LotConfig\n",
    "lotconfig_codes = {'CulDSac': 1, 'Corner': 2, 'FR2': 3, 'FR3': 4, 'Inside': 5}\n",
    "#LandSlope\n",
    "landslope_codes = {'Sev': 1, 'Mod': 2, 'Gtl': 3}\n",
    "#Neighborhood\n",
    "#inaccuracy in dataset:\n",
    "# not 'Names' but 'NAmes'\n",
    "neighborhood_codes = {\n",
    "    #1\n",
    "    'Blmngtn': 16, 'Blueste': 8, 'BrDale': 3, 'BrkSide': 6, 'ClearCr': 18, 'CollgCr': 17, 'Crawfor': 19, 'Edwards': 5,  'Gilbert': 14, \n",
    "    #10    \n",
    "    'IDOTRR': 2, 'MeadowV': 1, 'Mitchel': 12, 'NAmes': 10, 'NoRidge': 24, 'NPkVill': 11,  'NridgHt': 25, 'NWAmes': 15,  'OldTown': 4, 'SWISU': 9, \n",
    "    #20\n",
    "    'Sawyer': 7, 'SawyerW': 13, 'Somerst': 21, 'StoneBr': 23, 'Timber': 22,  'Veenker': 20\n",
    "}\n",
    "\n",
    "#Condition 1 and 2\n",
    "condition_codes = {\n",
    "    'Artery': 1, 'Feedr': 2, 'Norm': 3, 'RRNn': 4, 'RRAn': 5,\n",
    "    'PosN': 6, 'PosA': 7, 'RRNe': 8, 'RRAe': 9\n",
    "}\n",
    "\n",
    "#OverallCond sort by style's median price\n",
    "overallcond_codes = {\n",
    "    1: 1, 2: 2, 9: 3, 3: 4, 4: 5,\n",
    "    8: 6, 7: 7, 6: 8, 5: 9\n",
    "}\n",
    "\n",
    "#BldgType\n",
    "#inaccuracy in dataset:\n",
    "# not 'TwnhsI' but 'Twnhs'\n",
    "# not '2FmCon' but '2fmCon'\n",
    "# not 'Duplx' but 'Duplex'\n",
    "bldgtype_codes = {'TwnhsE': 1, 'Twnhs': 2, '1Fam': 3, '2fmCon': 4, 'Duplex': 5}\n",
    "\n",
    "#HouseStyle sort by style's median price\n",
    "housestyle_codes = {'1.5Unf': 1, '1.5Fin': 2, '2.5Unf': 3, 'SFoyer': 4, '1Story': 5, 'SLvl': 6, '2Story': 7, '2.5Fin': 8}\n",
    "\n",
    "#RoofStyle\n",
    "roofstyle_codes = {'Flat': 1, 'Gable': 2, 'Gambrel': 3, 'Hip': 4, 'Mansard': 5, 'Shed': 6}\n",
    "\n",
    "#RoofMatl\n",
    "roofmatl_codes = {'Membran': 1, 'WdShake': 2, 'WdShngl': 3, 'Roll': 4, 'Tar&Grv': 5, 'Metal': 6, 'CompShg': 7, 'ClyTile': 8}\n",
    "\n",
    "#Exterior 1st and 2nd \n",
    "#inaccuracy in dataset:\n",
    "# neither 'WdShing' not 'Wd Sdng' but 'Wd Shng'\n",
    "# not 'CemntBd' but 'CmentBd'\n",
    "# not 'BrkComm' but 'Brk Cmn'\n",
    "exterior_codes = {\n",
    "    'WdShing': 1, 'Wd Shng': 1, 'Wd Sdng': 2, 'AsbShng': 3, 'AsphShn': 4, 'CBlock': 5, 'CmentBd': 6, 'CemntBd': 6,\n",
    "    'HdBoard': 7, 'Stone': 8, 'PreCast': 9, 'Other': 10, 'Plywood': 11, 'BrkComm': 12, 'Brk Cmn': 12,\n",
    "    'VinylSd': 13, 'MetalSd': 14, 'Stucco': 15, 'ImStucc': 16, 'BrkFace': 17\n",
    "} \n",
    "\n",
    "#MasVnrType\n",
    "masvnrtype_codes = {'None': 1, 'Stone': 2, 'CBlock': 3, 'BrkCmn': 4, 'BrkFace': 5}\n",
    "\n",
    "#ExterQual\n",
    "#ExterCond\n",
    "#HeatingQC\n",
    "#KitchenQual\n",
    "fivelevel_codes = {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5} \n",
    "\n",
    "#BsmtQual\n",
    "#BsmtCond\n",
    "#FireplaceQu\n",
    "#GarageQual\n",
    "#GarageCond\n",
    "sixlevel_codes = {'NA': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n",
    "\n",
    "#Foundation\n",
    "foundation_codes = {'Wood': 1, 'BrkTil': 2, 'CBlock': 3, 'Stone': 4, 'Slab': 5, 'PConc': 6} \n",
    "\n",
    "#BsmtExposure\n",
    "bsmtexposure_codes = {'Gd': 1, 'Av': 2, 'Mn': 3, 'No': 4, 'NA': 5}\n",
    "\n",
    "#BsmtFinType1 and BsmtFinType2\n",
    "bsmtfintype_codes = {'NA': 1, 'Unf': 2, 'LwQ': 3, 'Rec': 4, 'BLQ': 5, 'ALQ': 6, 'GLQ': 7}\n",
    "\n",
    "#Heating\n",
    "heating_codes = {'Wall': 1, 'OthW': 2, 'Floor': 3, 'GasA': 4, 'Grav': 5, 'GasW': 6}\n",
    "\n",
    "#CentralAir\n",
    "yno_codes = {'N': 0, 'Y': 1}\n",
    "\n",
    "#Electrical\n",
    "electrical_codes = {'FuseP': 1, 'FuseF': 2, 'Mix': 3, 'FuseA': 4, 'SBrkr': 5}\n",
    "\n",
    "#Functional\n",
    "functional_codes = {'Sal': 1, 'Sev': 2, 'Maj2': 3, 'Maj1': 4, 'Mod': 5, 'Min2': 6, 'Min1': 7, 'Typ': 8} \n",
    "\n",
    "# GarageType\n",
    "garagetype_codes = {\n",
    "    'NA': 1, 'CarPort': 2, 'Detchd': 3, 'Attchd': 4,\n",
    "    'Basment': 5, 'BuiltIn': 6, '2Types': 7\n",
    "}\n",
    "\n",
    "#GarageFinish\n",
    "garagefinish_codes = {'NA': 1, 'Unf': 2, 'RFn': 3, 'Fin': 4}\n",
    "\n",
    "#PavedDrive\n",
    "paveddrive_codes = {'N': 1, 'P': 2, 'Y': 3}\n",
    "\n",
    "#PoolQC\n",
    "poolqc_codes = {'NA': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5} \n",
    "\n",
    "#Fence\n",
    "fence_codes = {'NA': 1, 'MnWw': 2, 'GdWo': 3, 'MnPrv': 4, 'GdPrv': 5} \n",
    "\n",
    "#MiscFeature\n",
    "miscfeature_codes = {'NA': 0, 'Othr': 1, 'Shed': 1, 'Gar2': 1, 'Elev': 2, 'TenC': 2}\n",
    "\n",
    "#SaleType sort by type's median price\n",
    "saletype_codes = {\n",
    "    'Oth': 1, 'ConLI': 2, 'COD': 3, 'ConLD': 4, 'VWD': 5, 'ConLw': 6,\n",
    "    'WD': 7, 'CWD': 8, 'New': 9, 'Con': 10\n",
    "} \n",
    "\n",
    "#SaleCondition sort by condition's median price\n",
    "salecondition_codes = {'AdjLand': 1, 'Abnorml': 2, 'Family': 3, 'Alloca': 4, 'Normal': 5, 'Partial': 6} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handy_map(df):\n",
    "    #df.MSSubClass = df.MSSubClass.map(mssubclass_codes)\n",
    "    df['MSSubclass_category'] = df.MSSubClass.map(mssubclass_category_codes)\n",
    "    df.MSSubClass = df.MSSubClass.astype(np.int64, copy=False)\n",
    "    df.MSZoning = df.MSZoning.map(mszoning_codes).astype(np.int64, copy=False)\n",
    "    #df.Street = df.Street.map(street_codes).astype(np.int64, copy=False)\n",
    "    df.LotShape = df.LotShape.map(lotshape_codes).astype(np.int64, copy=False)\n",
    "    df.LandContour = df.LandContour.map(landcontour_codes).astype(np.int64, copy=False)\n",
    "    df.LotConfig = df.LotConfig.map(lotconfig_codes).astype(np.int64, copy=False)\n",
    "    df.Condition1 = df.Condition1.map(condition_codes).astype(np.int64, copy=False)\n",
    "    df.Neighborhood = df.Neighborhood.map(neighborhood_codes).astype(np.int64, copy=False)\n",
    "    df.BldgType = df.BldgType.map(bldgtype_codes).astype(np.int64, copy=False)\n",
    "    df.HouseStyle = df.HouseStyle.map(housestyle_codes).astype(np.int64, copy=False)\n",
    "    df.RoofStyle = df.RoofStyle.map(roofstyle_codes).astype(np.int64, copy=False)\n",
    "    df.Exterior1st = df.Exterior1st.map(exterior_codes).astype(np.int64, copy=False)\n",
    "    df.Exterior2nd = df.Exterior2nd.map(exterior_codes).astype(np.int64, copy=False)\n",
    "    df.MasVnrType = df.MasVnrType.map(masvnrtype_codes).astype(np.int64, copy=False)\n",
    "    df.ExterQual = df.ExterQual.map(fivelevel_codes).astype(np.int64, copy=False)\n",
    "    df.ExterCond = df.ExterCond.map(fivelevel_codes).astype(np.int64, copy=False)\n",
    "    df.HeatingQC = df.HeatingQC.map(fivelevel_codes).astype(np.int64, copy=False)\n",
    "    df.KitchenQual = df.KitchenQual.map(fivelevel_codes).astype(np.int64, copy=False)\n",
    "    df.Foundation = df.Foundation.map(foundation_codes).astype(np.int64, copy=False)\n",
    "\n",
    "    \n",
    "    df.FireplaceQu = df.FireplaceQu.map(sixlevel_codes).astype(np.int64, copy=False)\n",
    "\n",
    "    #df.CentralAir = df.CentralAir.map(yno_codes).astype(np.int64, copy=False)\n",
    "    #df.Electrical = df.Electrical.map(electrical_codes).astype(np.int64, copy=False)\n",
    "    #df.Functional = df.Functional.map(functional_codes).astype(np.int64, copy=False)\n",
    "    #df.PavedDrive = df.PavedDrive.map(paveddrive_codes).astype(np.int64, copy=False)\n",
    "    df.BsmtExposure = df.BsmtExposure.map(bsmtexposure_codes).astype(np.int64, copy=False)\n",
    "    df.SaleCondition = df.SaleCondition.map(salecondition_codes).astype(np.int64, copy=False)\n",
    "    df.SaleType = df.SaleType.map(saletype_codes).astype(np.int64, copy=False)\n",
    "    \n",
    "    #df.OverallCond = df.OverallCond.map(overallcond_codes).astype(np.int64, copy=False)\n",
    "\n",
    "    df.BsmtQual = df.BsmtQual.map(sixlevel_codes).astype(np.int64, copy=False)\n",
    "    df.BsmtCond = df.BsmtCond.map(sixlevel_codes).astype(np.int64, copy=False)\n",
    "    df.BsmtFinType1 = df.BsmtFinType1.map(bsmtfintype_codes).astype(np.int64, copy=False)\n",
    "    df.BsmtFinType2 = df.BsmtFinType2.map(bsmtfintype_codes).astype(np.int64, copy=False)\n",
    "    '''\n",
    "    df.BsmtFinSF1 = df.BsmtFinSF1.fillna(0)    \n",
    "    df.BsmtFinSF2 = df.BsmtFinSF2.fillna(0)        \n",
    "    df.BsmtUnfSF = df.BsmtUnfSF.fillna(0)    \n",
    "    df.TotalBsmtSF = df.TotalBsmtSF.fillna(0)   \n",
    "    df.GarageCars = df.GarageCars.fillna(0)\n",
    "    \n",
    "    cat_cols = ['MSSubClass', 'MSZoning', 'LotShape', 'LandContour', 'LotConfig', 'Neighborhood', 'Condition1',\n",
    "    'BldgType', 'HouseStyle', 'RoofStyle', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond',\n",
    "    'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC',\n",
    "    'KitchenQual', 'FireplaceQu', 'SaleType', 'SaleCondition'\n",
    "    ]    \n",
    "    '''\n",
    "    return df\n",
    "\n",
    "df_train = handy_map(df_train)\n",
    "test = handy_map(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_columns(df):\n",
    "    # общее количество ванн\n",
    "    df['TotalBath'] = df.FullBath + df.BsmtFullBath + .5 * (df.HalfBath)    \n",
    "    df.TotalBath = df.TotalBath.fillna(0)\n",
    "    #удаляем исходные колонки\n",
    "    df = df.drop(['FullBath'],1)\n",
    "    df = df.drop(['BsmtFullBath'],1)   \n",
    "    df = df.drop(['HalfBath'],1)\n",
    "\n",
    "    # общая площадь веранд\n",
    "    df['TotalPorchSF'] = df.OpenPorchSF + df.EnclosedPorch + 1\n",
    "    #удаляем исходные колонки\n",
    "    df = df.drop(['OpenPorchSF'],1)\n",
    "    df = df.drop(['EnclosedPorch'],1)    \n",
    "\n",
    "    df['TotalQual'] = 5 * df.OverallQual * df.OverallCond + 13 * df.ExterQual * df.ExterCond + 13 * df.KitchenQual\n",
    "    #удаляем исходные колонки\n",
    "    df = df.drop(['OverallQual'],1)\n",
    "    df = df.drop(['OverallCond'],1)\n",
    "    df = df.drop(['ExterQual'],1)\n",
    "    df = df.drop(['ExterCond'],1)\n",
    "    df = df.drop(['KitchenQual'],1)\n",
    "\n",
    "    df['BsmtTotalQual'] = df.BsmtQual * df.BsmtCond + \\\n",
    "        df.BsmtFinType1 * (df.BsmtFinSF1/(df.TotalBsmtSF + 1)) + \\\n",
    "        df.BsmtFinType2 * (df.BsmtFinSF2/(df.TotalBsmtSF + 1)) - \\\n",
    "        df.BsmtUnfSF/(df.TotalBsmtSF + 1)\n",
    "\n",
    "    #df['BsmtQualFin_1and2'] = (df.BsmtFinType1 * np.log(df.BsmtFinSF1 + 1) + df.BsmtFinType2 * np.log(df.BsmtFinSF2 + 1)) * np.log(df.TotalBsmtSF + 1)\n",
    "\n",
    "    #удаляем исходные колонки\n",
    "    '''df = df.drop(['BsmtQual'],1)\n",
    "    df = df.drop(['BsmtCond'],1)\n",
    "    df = df.drop(['BsmtFinType1'],1)\n",
    "    df = df.drop(['BsmtFinType2'],1)\n",
    "    df = df.drop(['BsmtFinSF1'],1)\n",
    "    df = df.drop(['BsmtFinSF2'],1)\n",
    "    df = df.drop(['TotalBsmtSF'],1)\n",
    "    df = df.drop(['BsmtUnfSF'],1)'''\n",
    "\n",
    "    return df\n",
    "\n",
    "df_train = add_columns(df_train)\n",
    "test = add_columns(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           Id  MSSubClass  MSZoning  LotFrontage   LotArea  LotShape  \\\n",
       "count 1460.00     1460.00   1460.00      1460.00   1460.00   1460.00   \n",
       "mean   730.50       56.90     37.14         0.02  10516.83     14.08   \n",
       "std    421.61       42.30      7.96         0.94   9981.26      5.82   \n",
       "min      1.00       20.00     10.00        -2.07   1300.00     10.00   \n",
       "25%    365.75       20.00     40.00        -0.40   7553.50     10.00   \n",
       "50%    730.50       50.00     40.00        -0.06   9478.50     10.00   \n",
       "75%   1095.25       70.00     40.00         0.42  11601.50     20.00   \n",
       "max   1460.00      190.00     50.00        10.44 215245.00     40.00   \n",
       "\n",
       "       LandContour  LotConfig  Neighborhood  Condition1  BldgType  HouseStyle  \\\n",
       "count      1460.00    1460.00       1460.00     1460.00   1460.00     1460.00   \n",
       "mean         20.50       4.13         12.84        3.03      2.91        5.28   \n",
       "std           4.50       1.43          6.69        0.88      0.71        1.55   \n",
       "min          10.00       1.00          1.00        1.00      1.00        1.00   \n",
       "25%          20.00       3.00          7.00        3.00      3.00        5.00   \n",
       "50%          20.00       5.00         13.00        3.00      3.00        5.00   \n",
       "75%          20.00       5.00         17.00        3.00      3.00        7.00   \n",
       "max          40.00       5.00         25.00        9.00      5.00        8.00   \n",
       "\n",
       "       YearBuilt  YearRemodAdd  RoofStyle  Exterior1st  Exterior2nd  \\\n",
       "count    1460.00       1460.00    1460.00      1460.00      1460.00   \n",
       "mean       -0.00          0.03       2.41        10.05         9.96   \n",
       "std         1.00          0.99       0.83         4.59         4.53   \n",
       "min        -3.28         -1.64       1.00         1.00         1.00   \n",
       "25%        -0.57         -0.83       2.00         7.00         7.00   \n",
       "50%         0.06          0.47       2.00        13.00        13.00   \n",
       "75%         0.95          0.94       2.00        13.00        13.00   \n",
       "max         1.28          1.23       6.00        17.00        17.00   \n",
       "\n",
       "       MasVnrType  MasVnrArea  Foundation  BsmtQual  BsmtCond  BsmtExposure  \\\n",
       "count     1460.00     1460.00     1460.00   1460.00   1460.00       1460.00   \n",
       "mean         2.34        0.01        4.26      3.57      3.01          3.34   \n",
       "std          1.81        1.01        1.60      0.68      0.28          1.04   \n",
       "min          1.00       -0.57        1.00      2.00      1.00          1.00   \n",
       "25%          1.00       -0.57        3.00      3.00      3.00          3.00   \n",
       "50%          1.00       -0.57        3.00      4.00      3.00          4.00   \n",
       "75%          5.00        0.35        6.00      4.00      3.00          4.00   \n",
       "max          5.00        8.35        6.00      5.00      4.00          4.00   \n",
       "\n",
       "       BsmtFinType1  BsmtFinSF1  BsmtFinType2  BsmtFinSF2  BsmtUnfSF  \\\n",
       "count       1460.00     1460.00       1460.00     1460.00    1460.00   \n",
       "mean           4.57        0.00          2.27       -0.02     567.24   \n",
       "std            2.07        1.00          0.87        0.95     441.87   \n",
       "min            2.00       -0.97          2.00       -0.29       0.00   \n",
       "25%            2.00       -0.97          2.00       -0.29     223.00   \n",
       "50%            5.00       -0.13          2.00       -0.29     477.50   \n",
       "75%            7.00        0.59          2.00       -0.29     808.00   \n",
       "max            7.00       11.42          7.00        8.42    2336.00   \n",
       "\n",
       "       TotalBsmtSF  HeatingQC  2ndFlrSF  GrLivArea  BedroomAbvGr  Fireplaces  \\\n",
       "count      1460.00    1460.00   1460.00    1460.00       1460.00     1460.00   \n",
       "mean       1057.43       4.15      0.02    1515.46          0.01        0.02   \n",
       "std         438.71       0.96      1.02     525.48          0.99        1.00   \n",
       "min           0.00       1.00     -0.79     334.00         -3.48       -0.92   \n",
       "25%         795.75       3.00     -0.79    1129.50         -1.05       -0.92   \n",
       "50%         991.50       5.00     -0.79    1464.00          0.17        0.62   \n",
       "75%        1298.25       5.00      0.91    1776.75          0.17        0.62   \n",
       "max        6110.00       5.00      4.03    5642.00          6.25        3.72   \n",
       "\n",
       "       FireplaceQu  GarageCars  WoodDeckSF  MoSold  YrSold  SaleType  \\\n",
       "count      1460.00     1460.00     1460.00 1460.00 1460.00   1460.00   \n",
       "mean          3.72        0.00       94.24    0.04    0.02      7.00   \n",
       "std           0.60        0.98      125.34    1.00    1.01      1.02   \n",
       "min           1.00       -2.32        0.00   -1.92   -1.36      1.00   \n",
       "25%           3.00       -1.01        0.00   -0.45   -0.60      7.00   \n",
       "50%           4.00        0.31        0.00   -0.08    0.16      7.00   \n",
       "75%           4.00        0.31      168.00    0.66    0.92      7.00   \n",
       "max           5.00        2.93      857.00    2.13    1.68     10.00   \n",
       "\n",
       "       SaleCondition  MSSubclass_category  TotalBath  TotalPorchSF  TotalQual  \\\n",
       "count        1460.00              1460.00    1460.00       1460.00    1460.00   \n",
       "mean            4.83                25.59      -0.01          0.97     181.35   \n",
       "std             0.89                 6.86       1.48          1.30      32.51   \n",
       "min             1.00                10.00      -2.22         -0.06      81.76   \n",
       "25%             5.00                20.00      -1.23         -0.06     156.16   \n",
       "50%             5.00                30.00      -0.32          0.53     168.59   \n",
       "75%             5.00                30.00       0.68          1.49     206.36   \n",
       "max             6.00                30.00       7.11          9.47     419.82   \n",
       "\n",
       "       BsmtTotalQual  \n",
       "count        1460.00  \n",
       "mean           10.18  \n",
       "std             2.55  \n",
       "min             1.00  \n",
       "25%             8.45  \n",
       "50%            11.00  \n",
       "75%            11.70  \n",
       "max            19.98  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>LotConfig</th>\n      <th>Neighborhood</th>\n      <th>Condition1</th>\n      <th>BldgType</th>\n      <th>HouseStyle</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>RoofStyle</th>\n      <th>Exterior1st</th>\n      <th>Exterior2nd</th>\n      <th>MasVnrType</th>\n      <th>MasVnrArea</th>\n      <th>Foundation</th>\n      <th>BsmtQual</th>\n      <th>BsmtCond</th>\n      <th>BsmtExposure</th>\n      <th>BsmtFinType1</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinType2</th>\n      <th>BsmtFinSF2</th>\n      <th>BsmtUnfSF</th>\n      <th>TotalBsmtSF</th>\n      <th>HeatingQC</th>\n      <th>2ndFlrSF</th>\n      <th>GrLivArea</th>\n      <th>BedroomAbvGr</th>\n      <th>Fireplaces</th>\n      <th>FireplaceQu</th>\n      <th>GarageCars</th>\n      <th>WoodDeckSF</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>MSSubclass_category</th>\n      <th>TotalBath</th>\n      <th>TotalPorchSF</th>\n      <th>TotalQual</th>\n      <th>BsmtTotalQual</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>730.50</td>\n      <td>56.90</td>\n      <td>37.14</td>\n      <td>0.02</td>\n      <td>10516.83</td>\n      <td>14.08</td>\n      <td>20.50</td>\n      <td>4.13</td>\n      <td>12.84</td>\n      <td>3.03</td>\n      <td>2.91</td>\n      <td>5.28</td>\n      <td>-0.00</td>\n      <td>0.03</td>\n      <td>2.41</td>\n      <td>10.05</td>\n      <td>9.96</td>\n      <td>2.34</td>\n      <td>0.01</td>\n      <td>4.26</td>\n      <td>3.57</td>\n      <td>3.01</td>\n      <td>3.34</td>\n      <td>4.57</td>\n      <td>0.00</td>\n      <td>2.27</td>\n      <td>-0.02</td>\n      <td>567.24</td>\n      <td>1057.43</td>\n      <td>4.15</td>\n      <td>0.02</td>\n      <td>1515.46</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>3.72</td>\n      <td>0.00</td>\n      <td>94.24</td>\n      <td>0.04</td>\n      <td>0.02</td>\n      <td>7.00</td>\n      <td>4.83</td>\n      <td>25.59</td>\n      <td>-0.01</td>\n      <td>0.97</td>\n      <td>181.35</td>\n      <td>10.18</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>421.61</td>\n      <td>42.30</td>\n      <td>7.96</td>\n      <td>0.94</td>\n      <td>9981.26</td>\n      <td>5.82</td>\n      <td>4.50</td>\n      <td>1.43</td>\n      <td>6.69</td>\n      <td>0.88</td>\n      <td>0.71</td>\n      <td>1.55</td>\n      <td>1.00</td>\n      <td>0.99</td>\n      <td>0.83</td>\n      <td>4.59</td>\n      <td>4.53</td>\n      <td>1.81</td>\n      <td>1.01</td>\n      <td>1.60</td>\n      <td>0.68</td>\n      <td>0.28</td>\n      <td>1.04</td>\n      <td>2.07</td>\n      <td>1.00</td>\n      <td>0.87</td>\n      <td>0.95</td>\n      <td>441.87</td>\n      <td>438.71</td>\n      <td>0.96</td>\n      <td>1.02</td>\n      <td>525.48</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>0.60</td>\n      <td>0.98</td>\n      <td>125.34</td>\n      <td>1.00</td>\n      <td>1.01</td>\n      <td>1.02</td>\n      <td>0.89</td>\n      <td>6.86</td>\n      <td>1.48</td>\n      <td>1.30</td>\n      <td>32.51</td>\n      <td>2.55</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00</td>\n      <td>20.00</td>\n      <td>10.00</td>\n      <td>-2.07</td>\n      <td>1300.00</td>\n      <td>10.00</td>\n      <td>10.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>-3.28</td>\n      <td>-1.64</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>-0.57</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>-0.97</td>\n      <td>2.00</td>\n      <td>-0.29</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>-0.79</td>\n      <td>334.00</td>\n      <td>-3.48</td>\n      <td>-0.92</td>\n      <td>1.00</td>\n      <td>-2.32</td>\n      <td>0.00</td>\n      <td>-1.92</td>\n      <td>-1.36</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>10.00</td>\n      <td>-2.22</td>\n      <td>-0.06</td>\n      <td>81.76</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>365.75</td>\n      <td>20.00</td>\n      <td>40.00</td>\n      <td>-0.40</td>\n      <td>7553.50</td>\n      <td>10.00</td>\n      <td>20.00</td>\n      <td>3.00</td>\n      <td>7.00</td>\n      <td>3.00</td>\n      <td>3.00</td>\n      <td>5.00</td>\n      <td>-0.57</td>\n      <td>-0.83</td>\n      <td>2.00</td>\n      <td>7.00</td>\n      <td>7.00</td>\n      <td>1.00</td>\n      <td>-0.57</td>\n      <td>3.00</td>\n      <td>3.00</td>\n      <td>3.00</td>\n      <td>3.00</td>\n      <td>2.00</td>\n      <td>-0.97</td>\n      <td>2.00</td>\n      <td>-0.29</td>\n      <td>223.00</td>\n      <td>795.75</td>\n      <td>3.00</td>\n      <td>-0.79</td>\n      <td>1129.50</td>\n      <td>-1.05</td>\n      <td>-0.92</td>\n      <td>3.00</td>\n      <td>-1.01</td>\n      <td>0.00</td>\n      <td>-0.45</td>\n      <td>-0.60</td>\n      <td>7.00</td>\n      <td>5.00</td>\n      <td>20.00</td>\n      <td>-1.23</td>\n      <td>-0.06</td>\n      <td>156.16</td>\n      <td>8.45</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>730.50</td>\n      <td>50.00</td>\n      <td>40.00</td>\n      <td>-0.06</td>\n      <td>9478.50</td>\n      <td>10.00</td>\n      <td>20.00</td>\n      <td>5.00</td>\n      <td>13.00</td>\n      <td>3.00</td>\n      <td>3.00</td>\n      <td>5.00</td>\n      <td>0.06</td>\n      <td>0.47</td>\n      <td>2.00</td>\n      <td>13.00</td>\n      <td>13.00</td>\n      <td>1.00</td>\n      <td>-0.57</td>\n      <td>3.00</td>\n      <td>4.00</td>\n      <td>3.00</td>\n      <td>4.00</td>\n      <td>5.00</td>\n      <td>-0.13</td>\n      <td>2.00</td>\n      <td>-0.29</td>\n      <td>477.50</td>\n      <td>991.50</td>\n      <td>5.00</td>\n      <td>-0.79</td>\n      <td>1464.00</td>\n      <td>0.17</td>\n      <td>0.62</td>\n      <td>4.00</td>\n      <td>0.31</td>\n      <td>0.00</td>\n      <td>-0.08</td>\n      <td>0.16</td>\n      <td>7.00</td>\n      <td>5.00</td>\n      <td>30.00</td>\n      <td>-0.32</td>\n      <td>0.53</td>\n      <td>168.59</td>\n      <td>11.00</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1095.25</td>\n      <td>70.00</td>\n      <td>40.00</td>\n      <td>0.42</td>\n      <td>11601.50</td>\n      <td>20.00</td>\n      <td>20.00</td>\n      <td>5.00</td>\n      <td>17.00</td>\n      <td>3.00</td>\n      <td>3.00</td>\n      <td>7.00</td>\n      <td>0.95</td>\n      <td>0.94</td>\n      <td>2.00</td>\n      <td>13.00</td>\n      <td>13.00</td>\n      <td>5.00</td>\n      <td>0.35</td>\n      <td>6.00</td>\n      <td>4.00</td>\n      <td>3.00</td>\n      <td>4.00</td>\n      <td>7.00</td>\n      <td>0.59</td>\n      <td>2.00</td>\n      <td>-0.29</td>\n      <td>808.00</td>\n      <td>1298.25</td>\n      <td>5.00</td>\n      <td>0.91</td>\n      <td>1776.75</td>\n      <td>0.17</td>\n      <td>0.62</td>\n      <td>4.00</td>\n      <td>0.31</td>\n      <td>168.00</td>\n      <td>0.66</td>\n      <td>0.92</td>\n      <td>7.00</td>\n      <td>5.00</td>\n      <td>30.00</td>\n      <td>0.68</td>\n      <td>1.49</td>\n      <td>206.36</td>\n      <td>11.70</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1460.00</td>\n      <td>190.00</td>\n      <td>50.00</td>\n      <td>10.44</td>\n      <td>215245.00</td>\n      <td>40.00</td>\n      <td>40.00</td>\n      <td>5.00</td>\n      <td>25.00</td>\n      <td>9.00</td>\n      <td>5.00</td>\n      <td>8.00</td>\n      <td>1.28</td>\n      <td>1.23</td>\n      <td>6.00</td>\n      <td>17.00</td>\n      <td>17.00</td>\n      <td>5.00</td>\n      <td>8.35</td>\n      <td>6.00</td>\n      <td>5.00</td>\n      <td>4.00</td>\n      <td>4.00</td>\n      <td>7.00</td>\n      <td>11.42</td>\n      <td>7.00</td>\n      <td>8.42</td>\n      <td>2336.00</td>\n      <td>6110.00</td>\n      <td>5.00</td>\n      <td>4.03</td>\n      <td>5642.00</td>\n      <td>6.25</td>\n      <td>3.72</td>\n      <td>5.00</td>\n      <td>2.93</td>\n      <td>857.00</td>\n      <td>2.13</td>\n      <td>1.68</td>\n      <td>10.00</td>\n      <td>6.00</td>\n      <td>30.00</td>\n      <td>7.11</td>\n      <td>9.47</td>\n      <td>419.82</td>\n      <td>19.98</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 292
    }
   ],
   "source": [
    "df_train.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(df, col):\n",
    "    zero = df[df[col] == 0].shape[0] \n",
    "    if zero:\n",
    "        hascol = 'Has'+ col\n",
    "        df[hascol] = pd.Series(len(df[col]), index=df.index)\n",
    "        df[hascol] = 0 \n",
    "        df.loc[df[col]>0, hascol] = 1\n",
    "        df.loc[df[hascol]==1, col] = np.log(df[col])\n",
    "        df = df.drop([hascol],1)\n",
    "    else:\n",
    "        df[col] = np.log(df[col])\n",
    "\n",
    "log_transform(target, 'SalePrice')\n",
    "\n",
    "for c in log_transformation_col:\n",
    "    log_transform(df_train, c)\n",
    "    log_transform(test, c)"
   ]
  },
  {
   "source": [
    "## Feature Importance: Random Forest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           Id  MSSubClass  MSZoning  LotFrontage  LotArea  LotShape  \\\n",
       "count 1460.00     1460.00   1460.00      1460.00  1460.00   1460.00   \n",
       "mean   730.50       56.90     37.14         0.02     9.11     14.08   \n",
       "std    421.61       42.30      7.96         0.94     0.52      5.82   \n",
       "min      1.00       20.00     10.00        -2.07     7.17     10.00   \n",
       "25%    365.75       20.00     40.00        -0.40     8.93     10.00   \n",
       "50%    730.50       50.00     40.00        -0.06     9.16     10.00   \n",
       "75%   1095.25       70.00     40.00         0.42     9.36     20.00   \n",
       "max   1460.00      190.00     50.00        10.44    12.28     40.00   \n",
       "\n",
       "       LandContour  LotConfig  Neighborhood  Condition1  BldgType  HouseStyle  \\\n",
       "count      1460.00    1460.00       1460.00     1460.00   1460.00     1460.00   \n",
       "mean         20.50       4.13         12.84        3.03      2.91        5.28   \n",
       "std           4.50       1.43          6.69        0.88      0.71        1.55   \n",
       "min          10.00       1.00          1.00        1.00      1.00        1.00   \n",
       "25%          20.00       3.00          7.00        3.00      3.00        5.00   \n",
       "50%          20.00       5.00         13.00        3.00      3.00        5.00   \n",
       "75%          20.00       5.00         17.00        3.00      3.00        7.00   \n",
       "max          40.00       5.00         25.00        9.00      5.00        8.00   \n",
       "\n",
       "       YearBuilt  YearRemodAdd  RoofStyle  Exterior1st  Exterior2nd  \\\n",
       "count    1460.00       1460.00    1460.00      1460.00      1460.00   \n",
       "mean       -0.00          0.03       2.41        10.05         9.96   \n",
       "std         1.00          0.99       0.83         4.59         4.53   \n",
       "min        -3.28         -1.64       1.00         1.00         1.00   \n",
       "25%        -0.57         -0.83       2.00         7.00         7.00   \n",
       "50%         0.06          0.47       2.00        13.00        13.00   \n",
       "75%         0.95          0.94       2.00        13.00        13.00   \n",
       "max         1.28          1.23       6.00        17.00        17.00   \n",
       "\n",
       "       MasVnrType  MasVnrArea  Foundation  BsmtQual  BsmtCond  BsmtExposure  \\\n",
       "count     1460.00     1460.00     1460.00   1460.00   1460.00       1460.00   \n",
       "mean         2.34        0.01        4.26      3.57      3.01          3.34   \n",
       "std          1.81        1.01        1.60      0.68      0.28          1.04   \n",
       "min          1.00       -0.57        1.00      2.00      1.00          1.00   \n",
       "25%          1.00       -0.57        3.00      3.00      3.00          3.00   \n",
       "50%          1.00       -0.57        3.00      4.00      3.00          4.00   \n",
       "75%          5.00        0.35        6.00      4.00      3.00          4.00   \n",
       "max          5.00        8.35        6.00      5.00      4.00          4.00   \n",
       "\n",
       "       BsmtFinType1  BsmtFinSF1  BsmtFinType2  BsmtFinSF2  BsmtUnfSF  \\\n",
       "count       1460.00     1460.00       1460.00     1460.00    1460.00   \n",
       "mean           4.57        0.00          2.27       -0.02       5.65   \n",
       "std            2.07        1.00          0.87        0.95       1.85   \n",
       "min            2.00       -0.97          2.00       -0.29       0.00   \n",
       "25%            2.00       -0.97          2.00       -0.29       5.41   \n",
       "50%            5.00       -0.13          2.00       -0.29       6.17   \n",
       "75%            7.00        0.59          2.00       -0.29       6.69   \n",
       "max            7.00       11.42          7.00        8.42       7.76   \n",
       "\n",
       "       TotalBsmtSF  HeatingQC  2ndFlrSF  GrLivArea  BedroomAbvGr  Fireplaces  \\\n",
       "count      1460.00    1460.00   1460.00    1460.00       1460.00     1460.00   \n",
       "mean          6.75       4.15      0.02       7.27          0.01        0.02   \n",
       "std           1.15       0.96      1.02       0.33          0.99        1.00   \n",
       "min           0.00       1.00     -0.79       5.81         -3.48       -0.92   \n",
       "25%           6.68       3.00     -0.79       7.03         -1.05       -0.92   \n",
       "50%           6.90       5.00     -0.79       7.29          0.17        0.62   \n",
       "75%           7.17       5.00      0.91       7.48          0.17        0.62   \n",
       "max           8.72       5.00      4.03       8.64          6.25        3.72   \n",
       "\n",
       "       FireplaceQu  GarageCars  WoodDeckSF  MoSold  YrSold  SaleType  \\\n",
       "count      1460.00     1460.00     1460.00 1460.00 1460.00   1460.00   \n",
       "mean          3.72        0.00        2.45    0.04    0.02      7.00   \n",
       "std           0.60        0.98        2.59    1.00    1.01      1.02   \n",
       "min           1.00       -2.32        0.00   -1.92   -1.36      1.00   \n",
       "25%           3.00       -1.01        0.00   -0.45   -0.60      7.00   \n",
       "50%           4.00        0.31        0.00   -0.08    0.16      7.00   \n",
       "75%           4.00        0.31        5.12    0.66    0.92      7.00   \n",
       "max           5.00        2.93        6.75    2.13    1.68     10.00   \n",
       "\n",
       "       SaleCondition  MSSubclass_category  TotalBath  TotalPorchSF  TotalQual  \\\n",
       "count        1460.00              1460.00    1460.00        946.00    1460.00   \n",
       "mean            4.83                25.59      -0.01          0.09     181.35   \n",
       "std             0.89                 6.86       1.48          0.84      32.51   \n",
       "min             1.00                10.00      -2.22         -2.46      81.76   \n",
       "25%             5.00                20.00      -1.23         -0.53     156.16   \n",
       "50%             5.00                30.00      -0.32          0.08     168.59   \n",
       "75%             5.00                30.00       0.68          0.73     206.36   \n",
       "max             6.00                30.00       7.11          2.25     419.82   \n",
       "\n",
       "       BsmtTotalQual  HasTotalBsmtSF  HasBsmtUnfSF  HasWoodDeckSF  \n",
       "count        1460.00         1460.00       1460.00        1460.00  \n",
       "mean           10.18            0.97          0.92           0.48  \n",
       "std             2.55            0.16          0.27           0.50  \n",
       "min             1.00            0.00          0.00           0.00  \n",
       "25%             8.45            1.00          1.00           0.00  \n",
       "50%            11.00            1.00          1.00           0.00  \n",
       "75%            11.70            1.00          1.00           1.00  \n",
       "max            19.98            1.00          1.00           1.00  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>MSSubClass</th>\n      <th>MSZoning</th>\n      <th>LotFrontage</th>\n      <th>LotArea</th>\n      <th>LotShape</th>\n      <th>LandContour</th>\n      <th>LotConfig</th>\n      <th>Neighborhood</th>\n      <th>Condition1</th>\n      <th>BldgType</th>\n      <th>HouseStyle</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>RoofStyle</th>\n      <th>Exterior1st</th>\n      <th>Exterior2nd</th>\n      <th>MasVnrType</th>\n      <th>MasVnrArea</th>\n      <th>Foundation</th>\n      <th>BsmtQual</th>\n      <th>BsmtCond</th>\n      <th>BsmtExposure</th>\n      <th>BsmtFinType1</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinType2</th>\n      <th>BsmtFinSF2</th>\n      <th>BsmtUnfSF</th>\n      <th>TotalBsmtSF</th>\n      <th>HeatingQC</th>\n      <th>2ndFlrSF</th>\n      <th>GrLivArea</th>\n      <th>BedroomAbvGr</th>\n      <th>Fireplaces</th>\n      <th>FireplaceQu</th>\n      <th>GarageCars</th>\n      <th>WoodDeckSF</th>\n      <th>MoSold</th>\n      <th>YrSold</th>\n      <th>SaleType</th>\n      <th>SaleCondition</th>\n      <th>MSSubclass_category</th>\n      <th>TotalBath</th>\n      <th>TotalPorchSF</th>\n      <th>TotalQual</th>\n      <th>BsmtTotalQual</th>\n      <th>HasTotalBsmtSF</th>\n      <th>HasBsmtUnfSF</th>\n      <th>HasWoodDeckSF</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>946.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n      <td>1460.00</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>730.50</td>\n      <td>56.90</td>\n      <td>37.14</td>\n      <td>0.02</td>\n      <td>9.11</td>\n      <td>14.08</td>\n      <td>20.50</td>\n      <td>4.13</td>\n      <td>12.84</td>\n      <td>3.03</td>\n      <td>2.91</td>\n      <td>5.28</td>\n      <td>-0.00</td>\n      <td>0.03</td>\n      <td>2.41</td>\n      <td>10.05</td>\n      <td>9.96</td>\n      <td>2.34</td>\n      <td>0.01</td>\n      <td>4.26</td>\n      <td>3.57</td>\n      <td>3.01</td>\n      <td>3.34</td>\n      <td>4.57</td>\n      <td>0.00</td>\n      <td>2.27</td>\n      <td>-0.02</td>\n      <td>5.65</td>\n      <td>6.75</td>\n      <td>4.15</td>\n      <td>0.02</td>\n      <td>7.27</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>3.72</td>\n      <td>0.00</td>\n      <td>2.45</td>\n      <td>0.04</td>\n      <td>0.02</td>\n      <td>7.00</td>\n      <td>4.83</td>\n      <td>25.59</td>\n      <td>-0.01</td>\n      <td>0.09</td>\n      <td>181.35</td>\n      <td>10.18</td>\n      <td>0.97</td>\n      <td>0.92</td>\n      <td>0.48</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>421.61</td>\n      <td>42.30</td>\n      <td>7.96</td>\n      <td>0.94</td>\n      <td>0.52</td>\n      <td>5.82</td>\n      <td>4.50</td>\n      <td>1.43</td>\n      <td>6.69</td>\n      <td>0.88</td>\n      <td>0.71</td>\n      <td>1.55</td>\n      <td>1.00</td>\n      <td>0.99</td>\n      <td>0.83</td>\n      <td>4.59</td>\n      <td>4.53</td>\n      <td>1.81</td>\n      <td>1.01</td>\n      <td>1.60</td>\n      <td>0.68</td>\n      <td>0.28</td>\n      <td>1.04</td>\n      <td>2.07</td>\n      <td>1.00</td>\n      <td>0.87</td>\n      <td>0.95</td>\n      <td>1.85</td>\n      <td>1.15</td>\n      <td>0.96</td>\n      <td>1.02</td>\n      <td>0.33</td>\n      <td>0.99</td>\n      <td>1.00</td>\n      <td>0.60</td>\n      <td>0.98</td>\n      <td>2.59</td>\n      <td>1.00</td>\n      <td>1.01</td>\n      <td>1.02</td>\n      <td>0.89</td>\n      <td>6.86</td>\n      <td>1.48</td>\n      <td>0.84</td>\n      <td>32.51</td>\n      <td>2.55</td>\n      <td>0.16</td>\n      <td>0.27</td>\n      <td>0.50</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.00</td>\n      <td>20.00</td>\n      <td>10.00</td>\n      <td>-2.07</td>\n      <td>7.17</td>\n      <td>10.00</td>\n      <td>10.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>-3.28</td>\n      <td>-1.64</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>-0.57</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>2.00</td>\n      <td>-0.97</td>\n      <td>2.00</td>\n      <td>-0.29</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>1.00</td>\n      <td>-0.79</td>\n      <td>5.81</td>\n      <td>-3.48</td>\n      <td>-0.92</td>\n      <td>1.00</td>\n      <td>-2.32</td>\n      <td>0.00</td>\n      <td>-1.92</td>\n      <td>-1.36</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>10.00</td>\n      <td>-2.22</td>\n      <td>-2.46</td>\n      <td>81.76</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>365.75</td>\n      <td>20.00</td>\n      <td>40.00</td>\n      <td>-0.40</td>\n      <td>8.93</td>\n      <td>10.00</td>\n      <td>20.00</td>\n      <td>3.00</td>\n      <td>7.00</td>\n      <td>3.00</td>\n      <td>3.00</td>\n      <td>5.00</td>\n      <td>-0.57</td>\n      <td>-0.83</td>\n      <td>2.00</td>\n      <td>7.00</td>\n      <td>7.00</td>\n      <td>1.00</td>\n      <td>-0.57</td>\n      <td>3.00</td>\n      <td>3.00</td>\n      <td>3.00</td>\n      <td>3.00</td>\n      <td>2.00</td>\n      <td>-0.97</td>\n      <td>2.00</td>\n      <td>-0.29</td>\n      <td>5.41</td>\n      <td>6.68</td>\n      <td>3.00</td>\n      <td>-0.79</td>\n      <td>7.03</td>\n      <td>-1.05</td>\n      <td>-0.92</td>\n      <td>3.00</td>\n      <td>-1.01</td>\n      <td>0.00</td>\n      <td>-0.45</td>\n      <td>-0.60</td>\n      <td>7.00</td>\n      <td>5.00</td>\n      <td>20.00</td>\n      <td>-1.23</td>\n      <td>-0.53</td>\n      <td>156.16</td>\n      <td>8.45</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>730.50</td>\n      <td>50.00</td>\n      <td>40.00</td>\n      <td>-0.06</td>\n      <td>9.16</td>\n      <td>10.00</td>\n      <td>20.00</td>\n      <td>5.00</td>\n      <td>13.00</td>\n      <td>3.00</td>\n      <td>3.00</td>\n      <td>5.00</td>\n      <td>0.06</td>\n      <td>0.47</td>\n      <td>2.00</td>\n      <td>13.00</td>\n      <td>13.00</td>\n      <td>1.00</td>\n      <td>-0.57</td>\n      <td>3.00</td>\n      <td>4.00</td>\n      <td>3.00</td>\n      <td>4.00</td>\n      <td>5.00</td>\n      <td>-0.13</td>\n      <td>2.00</td>\n      <td>-0.29</td>\n      <td>6.17</td>\n      <td>6.90</td>\n      <td>5.00</td>\n      <td>-0.79</td>\n      <td>7.29</td>\n      <td>0.17</td>\n      <td>0.62</td>\n      <td>4.00</td>\n      <td>0.31</td>\n      <td>0.00</td>\n      <td>-0.08</td>\n      <td>0.16</td>\n      <td>7.00</td>\n      <td>5.00</td>\n      <td>30.00</td>\n      <td>-0.32</td>\n      <td>0.08</td>\n      <td>168.59</td>\n      <td>11.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1095.25</td>\n      <td>70.00</td>\n      <td>40.00</td>\n      <td>0.42</td>\n      <td>9.36</td>\n      <td>20.00</td>\n      <td>20.00</td>\n      <td>5.00</td>\n      <td>17.00</td>\n      <td>3.00</td>\n      <td>3.00</td>\n      <td>7.00</td>\n      <td>0.95</td>\n      <td>0.94</td>\n      <td>2.00</td>\n      <td>13.00</td>\n      <td>13.00</td>\n      <td>5.00</td>\n      <td>0.35</td>\n      <td>6.00</td>\n      <td>4.00</td>\n      <td>3.00</td>\n      <td>4.00</td>\n      <td>7.00</td>\n      <td>0.59</td>\n      <td>2.00</td>\n      <td>-0.29</td>\n      <td>6.69</td>\n      <td>7.17</td>\n      <td>5.00</td>\n      <td>0.91</td>\n      <td>7.48</td>\n      <td>0.17</td>\n      <td>0.62</td>\n      <td>4.00</td>\n      <td>0.31</td>\n      <td>5.12</td>\n      <td>0.66</td>\n      <td>0.92</td>\n      <td>7.00</td>\n      <td>5.00</td>\n      <td>30.00</td>\n      <td>0.68</td>\n      <td>0.73</td>\n      <td>206.36</td>\n      <td>11.70</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1460.00</td>\n      <td>190.00</td>\n      <td>50.00</td>\n      <td>10.44</td>\n      <td>12.28</td>\n      <td>40.00</td>\n      <td>40.00</td>\n      <td>5.00</td>\n      <td>25.00</td>\n      <td>9.00</td>\n      <td>5.00</td>\n      <td>8.00</td>\n      <td>1.28</td>\n      <td>1.23</td>\n      <td>6.00</td>\n      <td>17.00</td>\n      <td>17.00</td>\n      <td>5.00</td>\n      <td>8.35</td>\n      <td>6.00</td>\n      <td>5.00</td>\n      <td>4.00</td>\n      <td>4.00</td>\n      <td>7.00</td>\n      <td>11.42</td>\n      <td>7.00</td>\n      <td>8.42</td>\n      <td>7.76</td>\n      <td>8.72</td>\n      <td>5.00</td>\n      <td>4.03</td>\n      <td>8.64</td>\n      <td>6.25</td>\n      <td>3.72</td>\n      <td>5.00</td>\n      <td>2.93</td>\n      <td>6.75</td>\n      <td>2.13</td>\n      <td>1.68</td>\n      <td>10.00</td>\n      <td>6.00</td>\n      <td>30.00</td>\n      <td>7.11</td>\n      <td>2.25</td>\n      <td>419.82</td>\n      <td>19.98</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 297
    }
   ],
   "source": [
    "df_train.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-298-7308768bf994>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'max_features'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'max_depth'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'n_estimators'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m350\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mregr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mregr_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ml_common\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ml_common\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ml_common\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    303\u001b[0m             )\n\u001b[0;32m    304\u001b[0m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[1;32m--> 305\u001b[1;33m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0m\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ml_common\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ml_common\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ml_common\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    819\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 821\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    822\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    823\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ml_common\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ml_common\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    663\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 664\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    666\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ml_common\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                     (type_err,\n\u001b[1;32m--> 106\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m    107\u001b[0m             )\n\u001b[0;32m    108\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "regr = RandomForestRegressor(random_state=42)\n",
    "\n",
    "params = {'max_features': [13,15], 'max_depth': [25,28], 'n_estimators': [300, 350]}\n",
    "gs = GridSearchCV(regr, params)\n",
    "gs.fit(df_train, target)\n",
    "regr = gs.best_estimator_\n",
    "regr_score = gs.best_score_\n",
    "\n",
    "regr_importance = pd.Series(regr.feature_importances_)\n",
    "sorted_importance = regr_importance.sort_values(ascending=False)\n",
    "sorted_colnames = df_train.columns[sorted_importance.index]\n",
    "pd.Series(index=sorted_colnames, data=sorted_importance.values).head(30).plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "params = {'loss':('ls', 'huber'), 'n_estimators': [200, 300], 'learning_rate': [0.1, 0.2]}\n",
    "gs = GridSearchCV(gbr, params)\n",
    "gs.fit(df_train, target)\n",
    "gbr = gs.best_estimator_\n",
    "gbr_score = gs.best_score_\n",
    "\n",
    "gbr_importance = permutation_importance(gbr, df_train, target, scoring='neg_mean_squared_error').importances_mean\n",
    "pd.Series(data=gbr_importance, index=df_train.columns).sort_values(ascending=False).head(30).plot.bar();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "ada = AdaBoostRegressor(random_state=42)\n",
    "\n",
    "params = {'n_estimators':(50, 100, 200), 'learning_rate':(1, 1.1, 0.9), 'loss': ['linear', 'square', 'exponential']}\n",
    "gs = GridSearchCV(ada, params)\n",
    "gs.fit(df_train, target)\n",
    "ada = gs.best_estimator_\n",
    "ada_score = gs.best_score_\n",
    "\n",
    "ada_importance = permutation_importance(ada, df_train, target, scoring='neg_mean_squared_error').importances_mean\n",
    "pd.Series(data=ada_importance, index=df_train.columns).sort_values(ascending=False).head(30).plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ada)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "en = ElasticNet(random_state=42)\n",
    "\n",
    "params = {'selection':('cyclic', 'random'), 'alpha':(1.0, 0.8), 'l1_ratio':(.3, .5, .7)}\n",
    "gs = GridSearchCV(en, params)\n",
    "gs.fit(df_train, target)\n",
    "en = gs.best_estimator_\n",
    "en_score = gs.best_score_\n",
    "\n",
    "en_importance = permutation_importance(en, df_train, target, scoring='neg_mean_squared_error').importances_mean\n",
    "pd.Series(data=en_importance, index=df_train.columns).sort_values(ascending=False).head(30).plot.bar();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[regr_score, en_score, ada_score, gbr_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best column names are stored in best.index\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax = MinMaxScaler()\n",
    "regr_importance_s = pd.Series(minmax.fit_transform(regr_importance.values.reshape((-1,1))).flat)\n",
    "en_importance_s = pd.Series(minmax.fit_transform(en_importance.reshape((-1,1))).flat)\n",
    "ada_importance_s = pd.Series(minmax.fit_transform(ada_importance.reshape((-1,1))).flat)\n",
    "gbr_importance_s = pd.Series(minmax.fit_transform(gbr_importance.reshape((-1,1))).flat)\n",
    "\n",
    "importance_data = pd.Series(1/4*(regr_importance_s*regr_score + en_importance_s*en_score + ada_importance_s*ada_score + gbr_importance_s*gbr_score))\n",
    "importance = pd.Series(data=importance_data.values, index=df_train.columns)\n",
    "best = importance.sort_values(ascending=False).head(30)\n",
    "plot = best.plot.bar();\n",
    "\n",
    "plot.set_title('Best scoring Features')\n",
    "plot.set_xlabel('Feature')\n",
    "plot.set_ylabel('Sum of scores, weighted by model performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "params = {'loss':('ls', 'huber'), 'n_estimators': [200, 300], 'learning_rate': [0.1, 0.2]}\n",
    "gs = GridSearchCV(final, params)\n",
    "gs.fit(df_train[best.index], target)\n",
    "final = gs.best_estimator_\n",
    "final_score = gs.best_score_\n",
    "final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_final = RandomForestRegressor(random_state=42)\n",
    "\n",
    "params = {'max_features': [10,12], 'max_depth': [25], 'n_estimators': [300]}\n",
    "gs = GridSearchCV(rf_final, params)\n",
    "gs.fit(df_train[best.index], target)\n",
    "rf_final = gs.best_estimator_\n",
    "rf_final_score = gs.best_score_\n",
    "rf_final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_final = AdaBoostRegressor(random_state=42, learning_rate=1.1, loss='exponential')\n",
    "\n",
    "params = {'n_estimators':(200, 250)}\n",
    "gs = GridSearchCV(ada_final, params)\n",
    "gs.fit(df_train[best.index], target)\n",
    "ada_final = gs.best_estimator_\n",
    "ada_final_score = gs.best_score_\n",
    "ada_final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_final = ElasticNet(alpha=0.8, l1_ratio=0.7, random_state=42)\n",
    "\n",
    "params = {'selection':('cyclic', 'random')}\n",
    "gs = GridSearchCV(en_final, params)\n",
    "gs.fit(df_train[best.index], target)\n",
    "en_final = gs.best_estimator_\n",
    "en_final_score = gs.best_score_\n",
    "en_final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = 1/2*(final.predict(test[best.index]) + rf_final.predict(test[best.index]))\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_x_test = pd.DataFrame(data={'Id': test['Id'], 'SalePrice': preds})\n",
    "\n",
    "df_result_x_test['SalePrice'] = df_result_x_test['SalePrice'].astype(np.int64, copy=False)\n",
    "df_result_x_test.to_csv('rf_grid_submission_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#save datasets\n",
    "#target['SalePrice'] = np.log(target['SalePrice'])   \n",
    "\n",
    "df_train = pd.concat([df_train_id, df_train, target], axis=1)\n",
    "df_train.to_csv('train_norm_3.csv', index=False, na_rep='NA')\n",
    "\n",
    "test = pd.concat([test_id, test], axis=1)\n",
    "test.to_csv('test_norm_3.csv', index=False, na_rep='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}