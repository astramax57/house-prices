{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train contains data as is\n",
    "df_train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test contains data as is\n",
    "df_test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train contains 81 columns, 1460 rows\nTest contains 80 columns, 1459 rows\n"
     ]
    }
   ],
   "source": [
    "print(f'Train contains {df_train.shape[1]} columns, {df_train.shape[0]} rows')\n",
    "print(f'Test contains {df_test.shape[1]} columns, {df_test.shape[0]} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_columns(df):\n",
    "    #удаляем все колонки, в которых более 15% пустых значений - PoolQC, MiscFeatures, Alley, Fence, FirePlaceQu, LotFrontage\n",
    "    df = df.drop(['PoolQC'], 1)\n",
    "    df = df.drop(['MiscFeature'], 1)\n",
    "    df = df.drop(['Alley'], 1)\n",
    "    df = df.drop(['Fence'], 1)\n",
    "    df = df.drop(['FireplaceQu'], 1)\n",
    "    df = df.drop(['LotFrontage'], 1)\n",
    "\n",
    "    #в колонках GarageX одинаковое количество пропущенных значений\n",
    "    #при этом наиболее важная информация по гаражам содержится в колонке GarageCars\n",
    "    #следовательно, остальные колонки GarageX можно удалить\n",
    "    df = df.drop(['GarageCond'], 1)\n",
    "    df = df.drop(['GarageType'], 1)\n",
    "    df = df.drop(['GarageYrBlt'], 1)\n",
    "    df = df.drop(['GarageFinish'], 1)\n",
    "    df = df.drop(['GarageQual'], 1)\n",
    "    df = df.drop(['BsmtExposure'], 1)\n",
    "    df = df.drop(['BsmtFinType2'], 1)\n",
    "    df = df.drop(['BsmtFinType1'], 1)\n",
    "    df = df.drop(['BsmtCond'], 1)\n",
    "    df = df.drop(['BsmtQual'], 1)\n",
    "    df = df.drop(['MasVnrArea'], 1)\n",
    "    df = df.drop(['MasVnrType'], 1)\n",
    "\n",
    "    #удаляю переменные с низкой вариативностью\n",
    "    df = df.drop(['Utilities'],1)\n",
    "    df = df.drop(['BsmtFinSF2'],1)\n",
    "\n",
    "    #переменные, влияние которых не очевидно\n",
    "    df = df.drop(['Condition1'],1)\n",
    "    df = df.drop(['Condition2'],1)\n",
    "    df = df.drop(['RoofStyle'],1)\n",
    "    df = df.drop(['RoofMatl'],1)\n",
    "    df = df.drop(['Exterior1st'],1)\n",
    "    df = df.drop(['Exterior2nd'],1)\n",
    "    df = df.drop(['Heating'],1)\n",
    "    df = df.drop(['BedroomAbvGr'],1)\n",
    "    df = df.drop(['KitchenAbvGr'],1)\n",
    "    df = df.drop(['MiscVal'],1)\n",
    "\n",
    "    #числовые переменные с небольшим числом значений, отличных от 0\n",
    "    df = df.drop(['PoolArea'],1)\n",
    "\n",
    "    # удаляю переменные, имеющие значительную корреляцию с аналогичными по смыслу переменными\n",
    "    df = df.drop(['TotRmsAbvGrd'],1)\n",
    "    df = df.drop(['GarageArea'],1)\n",
    "    df = df.drop(['1stFlrSF'],1)\n",
    "    df = df.drop(['2ndFlrSF'],1)\n",
    "    df = df.drop(['LowQualFinSF'],1)\n",
    "    return df\n",
    "\n",
    "df_train = delete_columns(df_train)\n",
    "df_test = delete_columns(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train contains 45 columns, 1460 rows\nTest contains 44 columns, 1459 rows\n"
     ]
    }
   ],
   "source": [
    "print(f'Train contains {df_train.shape[1]} columns, {df_train.shape[0]} rows')\n",
    "print(f'Test contains {df_test.shape[1]} columns, {df_test.shape[0]} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем колонки \n",
    "\n",
    "def add_columns(df):\n",
    "    # общее количество ванн\n",
    "    df['TotalBath'] = df.FullBath + df.BsmtFullBath + .5 * (df.BsmtHalfBath + df.HalfBath)\n",
    "    \n",
    "    #удаляем исходные колонки\n",
    "    df = df.drop(['FullBath'],1)\n",
    "    df = df.drop(['BsmtFullBath'],1)\n",
    "    df = df.drop(['BsmtHalfBath'],1)\n",
    "    df = df.drop(['HalfBath'],1)\n",
    "\n",
    "    # общая площадь веранд\n",
    "    df['TotalPorchSF'] = df.OpenPorchSF + df.EnclosedPorch + df['3SsnPorch'] + df.ScreenPorch\n",
    "    #удаляем исходные колонки\n",
    "    df = df.drop(['OpenPorchSF'],1)\n",
    "    df = df.drop(['EnclosedPorch'],1)\n",
    "    df = df.drop(['3SsnPorch'],1)\n",
    "    df = df.drop(['ScreenPorch'],1)\n",
    "    return df\n",
    "\n",
    "df_train = add_columns(df_train)\n",
    "df_test = add_columns(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outliars in train dataset\n",
    "#Electrical имеет всего один пропуск, поэтому удаляем строку, а не колонку\n",
    "df_train = df_train.drop(df_train.loc[df_train['Electrical'].isnull()].index)\n",
    "#удаляем выбросы в соотношении цена\\площадь жилья\n",
    "df_train = df_train.drop(df_train[(df_train.SalePrice < 200000) & (df_train.GrLivArea > 4000)].index)\n",
    "#удаляем выбросы в площади участка\n",
    "df_train = df_train.drop(df_train[df_train.LotArea > 150000].index)\n",
    "#удаляем выбросы в количестве ванн\n",
    "df_train = df_train.drop(df_train[df_train.TotalBath > 4.5].index)\n",
    "#удаляем выбросы площади фундамента\n",
    "df_train = df_train.drop(df_train[df_train.TotalBsmtSF > 5000].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train contains 39 columns, 1455 rows\nTest contains 38 columns, 1459 rows\n"
     ]
    }
   ],
   "source": [
    "print(f'Train contains {df_train.shape[1]} columns, {df_train.shape[0]} rows')\n",
    "print(f'Test contains {df_test.shape[1]} columns, {df_test.shape[0]} rows')"
   ]
  },
  {
   "source": [
    "## лог-трансформация"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(df, col):\n",
    "    zero = df[df[col] == 0].shape[0]\n",
    "    #print(zero)    \n",
    "    if zero:\n",
    "        hascol = 'Has'+ col\n",
    "        df[hascol] = pd.Series(len(df[col]), index=df.index)\n",
    "        df[hascol] = 0 \n",
    "        df.loc[df[col]>0, hascol] = 1\n",
    "        df.loc[df[hascol]==1, col] = np.log(df[col])\n",
    "        df = df.drop([hascol],1)\n",
    "    else:\n",
    "        df[col] = np.log(df[col])\n",
    "\n",
    "log_transform(df_train, 'SalePrice')\n",
    "log_transform(df_train, 'GrLivArea')\n",
    "log_transform(df_train, 'TotalBsmtSF')\n",
    "log_transform(df_train, 'BsmtUnfSF')\n",
    "log_transform(df_train, 'WoodDeckSF')\n",
    "log_transform(df_train, 'TotalPorchSF')\n",
    "log_transform(df_train, 'LotArea')\n",
    "#\n",
    "\n",
    "log_transform(df_test, 'GrLivArea')\n",
    "log_transform(df_test, 'TotalBsmtSF')\n",
    "log_transform(df_test, 'BsmtUnfSF')\n",
    "log_transform(df_test, 'WoodDeckSF')\n",
    "log_transform(df_test, 'TotalPorchSF')\n",
    "log_transform(df_test, 'LotArea')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MSSubClass\n",
    "# 10 - low SalePrice median \n",
    "# 20 - medium SalePrice median \n",
    "# 30 - high SalePrice median \n",
    "mssubclass_category_codes = {\n",
    "    20: 30, 30: 10, 40: 20, 45: 10, 50: 30, 60: 30,\n",
    "    70: 20, 75: 20, 80: 20, 85: 10, 90: 10, 120: 20,\n",
    "    150: 20, 160: 20, 180: 10, 190: 20 \n",
    "}\n",
    " \n",
    "#MSZoning\n",
    "#only this codes in dataset: RL, RM, FV, RH, C (all)\n",
    "mszoning_codes = {'C (all)': 10, 'RM': 20, 'RH': 30, 'RL': 40, 'FV': 50}\n",
    "\n",
    "#Street\n",
    "street_codes = {'Grvl': 1, 'Pave': 2}\n",
    "\n",
    "#LotShape\n",
    "lotshape_codes = {'Reg': 10, 'IR1': 20, 'IR2': 30, 'IR3': 40}\n",
    "#LandContour\n",
    "landcontour_codes = {'Bnk': 10, 'Lvl': 20, 'Low': 30, 'HLS': 40}\n",
    "#Utilities\n",
    "utilities_codes = {'ELO': 1, 'NoSeWa': 2, 'NoSewr': 3, 'AllPub': 4}\n",
    "#LotConfig\n",
    "lotconfig_codes = {'CulDSac': 1, 'Corner': 2, 'FR2': 3, 'FR3': 4, 'Inside': 5}\n",
    "#LandSlope\n",
    "landslope_codes = {'Sev': 1, 'Mod': 2, 'Gtl': 3}\n",
    "#Neighborhood\n",
    "#inaccuracy in dataset:\n",
    "# not 'Names' but 'NAmes'\n",
    "neighborhood_codes_old = {\n",
    "    'Blmngtn': 1, 'Blueste': 2, 'BrDale': 3, 'BrkSide': 4, 'ClearCr': 5, 'CollgCr': 6,\n",
    "    'Crawfor': 7, 'Edwards': 8, 'Gilbert': 9, 'IDOTRR': 10, 'MeadowV': 11, 'Mitchel': 12,\n",
    "    'NAmes': 13, 'NoRidge': 14, 'NPkVill': 15, 'NridgHt': 16, 'NWAmes': 17, 'OldTown': 18,\n",
    "    'SWISU': 19, 'Sawyer': 20, 'SawyerW': 21, 'Somerst': 22, 'StoneBr': 23, 'Timber': 24, 'Veenker': 25\n",
    "}\n",
    "\n",
    "neighborhood_codes = {\n",
    "    #1\n",
    "    'Blmngtn': 16, 'Blueste': 8, 'BrDale': 3, 'BrkSide': 6, 'ClearCr': 18, 'CollgCr': 17, 'Crawfor': 19, 'Edwards': 5,  'Gilbert': 14, \n",
    "    #10    \n",
    "    'IDOTRR': 2, 'MeadowV': 1, 'Mitchel': 12, 'NAmes': 10, 'NoRidge': 24, 'NPkVill': 11,  'NridgHt': 25, 'NWAmes': 15,  'OldTown': 4, 'SWISU': 9, \n",
    "    #20\n",
    "    'Sawyer': 7, 'SawyerW': 13, 'Somerst': 21, 'StoneBr': 23, 'Timber': 22,  'Veenker': 20\n",
    "}\n",
    "\n",
    "#Condition 1 and 2\n",
    "condition_codes = {\n",
    "    'Artery': 1, 'Feedr': 2, 'Norm': 3, 'RRNn': 4, 'RRAn': 5,\n",
    "    'PosN': 6, 'PosA': 7, 'RRNe': 8, 'RRAe': 9\n",
    "}\n",
    "\n",
    "#BldgType\n",
    "#inaccuracy in dataset:\n",
    "# not 'TwnhsI' but 'Twnhs'\n",
    "# not '2FmCon' but '2fmCon'\n",
    "# not 'Duplx' but 'Duplex'\n",
    "bldgtype_codes = {'TwnhsE': 1, 'Twnhs': 2, '1Fam': 3, '2fmCon': 4, 'Duplex': 5}\n",
    "\n",
    "#HouseStyle\n",
    "housestyle_codes = {'1Story': 1, '1.5Unf': 2, '1.5Fin': 3, '2Story': 4, '2.5Unf': 5, '2.5Fin': 6, 'SFoyer': 7, 'SLvl': 8}\n",
    "\n",
    "#RoofStyle\n",
    "roofstyle_codes = {'Flat': 1, 'Gable': 2, 'Gambrel': 3, 'Hip': 4, 'Mansard': 5, 'Shed': 6}\n",
    "\n",
    "#RoofMatl\n",
    "roofmatl_codes = {'Membran': 1, 'WdShake': 2, 'WdShngl': 3, 'Roll': 4, 'Tar&Grv': 5, 'Metal': 6, 'CompShg': 7, 'ClyTile': 8}\n",
    "\n",
    "#Exterior 1st and 2nd \n",
    "#inaccuracy in dataset:\n",
    "# neither 'WdShing' not 'Wd Sdng' but 'Wd Shng'\n",
    "# not 'CemntBd' but 'CmentBd'\n",
    "# not 'BrkComm' but 'Brk Cmn'\n",
    "exterior_codes = {\n",
    "    'WdShing': 1, 'Wd Shng': 1, 'Wd Sdng': 2, 'AsbShng': 3, 'AsphShn': 4, 'CBlock': 5, 'CmentBd': 6, 'CemntBd': 6,\n",
    "    'HdBoard': 7, 'Stone': 8, 'PreCast': 9, 'Other': 10, 'Plywood': 11, 'BrkComm': 12, 'Brk Cmn': 12,\n",
    "    'VinylSd': 13, 'MetalSd': 14, 'Stucco': 15, 'ImStucc': 16, 'BrkFace': 17\n",
    "} \n",
    "\n",
    "#MasVnrType\n",
    "masvnrtype_codes = {'None': 1, 'Stone': 2, 'CBlock': 3, 'BrkCmn': 4, 'BrkFace': 5}\n",
    "\n",
    "#ExterQual\n",
    "#ExterCond\n",
    "#HeatingQC\n",
    "#KitchenQual\n",
    "fivelevel_codes = {'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5} \n",
    "\n",
    "#BsmtQual\n",
    "#BsmtCond\n",
    "#FireplaceQu\n",
    "#GarageQual\n",
    "#GarageCond\n",
    "sixlevel_codes = {'NA': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}\n",
    "\n",
    "#Foundation\n",
    "foundation_codes = {'Wood': 1, 'BrkTil': 2, 'CBlock': 3, 'Stone': 4, 'Slab': 5, 'PConc': 6} \n",
    "\n",
    "#BsmtExposure\n",
    "bsmtexposure_codes = {'Gd': 1, 'Av': 2, 'Mn': 3, 'No': 4, 'NA': 5}\n",
    "\n",
    "#BsmtFinType1 and BsmtFinType2\n",
    "bsmtfintype_codes = {'NA': 1, 'Unf': 2, 'LwQ': 3, 'Rec': 4, 'BLQ': 5, 'ALQ': 6, 'GLQ': 7}\n",
    "\n",
    "#Heating\n",
    "heating_codes = {'Wall': 1, 'OthW': 2, 'Floor': 3, 'GasA': 4, 'Grav': 5, 'GasW': 6}\n",
    "\n",
    "#CentralAir\n",
    "yno_codes = {'N': 0, 'Y': 1}\n",
    "\n",
    "#Electrical\n",
    "electrical_codes = {'FuseP': 1, 'FuseF': 2, 'Mix': 3, 'FuseA': 4, 'SBrkr': 5}\n",
    "\n",
    "#Functional\n",
    "functional_codes = {'Sal': 1, 'Sev': 2, 'Maj2': 3, 'Maj1': 4, 'Mod': 5, 'Min2': 6, 'Min1': 7, 'Typ': 8} \n",
    "\n",
    "# GarageType\n",
    "garagetype_codes = {\n",
    "    'NA': 1, 'CarPort': 2, 'Detchd': 3, 'Attchd': 4,\n",
    "    'Basment': 5, 'BuiltIn': 6, '2Types': 7\n",
    "}\n",
    "\n",
    "#GarageFinish\n",
    "garagefinish_codes = {'NA': 1, 'Unf': 2, 'RFn': 3, 'Fin': 4}\n",
    "\n",
    "#PavedDrive\n",
    "paveddrive_codes = {'N': 1, 'P': 2, 'Y': 3}\n",
    "\n",
    "#PoolQC\n",
    "poolqc_codes = {'NA': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5} \n",
    "\n",
    "#Fence\n",
    "fence_codes = {'NA': 1, 'MnWw': 2, 'GdWo': 3, 'MnPrv': 4, 'GdPrv': 5} \n",
    "\n",
    "#MiscFeature\n",
    "miscfeature_codes = {'NA': 0, 'Othr': 1, 'Shed': 1, 'Gar2': 1, 'Elev': 2, 'TenC': 2}\n",
    "\n",
    "#SaleType sort by type's median price\n",
    "saletype_codes = {\n",
    "    'Oth': 1, 'ConLI': 2, 'COD': 3, 'ConLD': 4, 'VWD': 5, 'ConLw': 6,\n",
    "    'WD': 7, 'CWD': 8, 'New': 9, 'Con': 10\n",
    "} \n",
    "\n",
    "#SaleCondition sort by condition's median price\n",
    "salecondition_codes = {'AdjLand': 1, 'Abnorml': 2, 'Family': 3, 'Alloca': 4, 'Normal': 5, 'Partial': 6} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_and_map(df):\n",
    "    #df.MSSubClass = df.MSSubClass.map(mssubclass_codes)\n",
    "    df['MSSubclass_category'] = df.MSSubClass.map(mssubclass_category_codes)\n",
    "    df.MSSubClass = df.MSSubClass.astype(np.int64, copy=False)\n",
    "    df.MSZoning = df.MSZoning.fillna(df['MSZoning'].mode()[0]).map(mszoning_codes).astype(np.int64, copy=False)\n",
    "    df.Street = df.Street.map(street_codes).astype(np.int64, copy=False)\n",
    "    df.LotShape = df.LotShape.map(lotshape_codes).astype(np.int64, copy=False)\n",
    "    df.LandContour = df.LandContour.map(landcontour_codes).astype(np.int64, copy=False)\n",
    "    df.LotConfig = df.LotConfig.map(lotconfig_codes).astype(np.int64, copy=False)\n",
    "    df.LandSlope = df.LandSlope.map(landslope_codes).astype(np.int64, copy=False)\n",
    "    df.Neighborhood = df.Neighborhood.map(neighborhood_codes).astype(np.int64, copy=False)\n",
    "    df.BldgType = df.BldgType.map(bldgtype_codes).astype(np.int64, copy=False)\n",
    "    df.HouseStyle = df.HouseStyle.map(housestyle_codes).astype(np.int64, copy=False)\n",
    "    df.ExterQual = df.ExterQual.map(fivelevel_codes).astype(np.int64, copy=False)\n",
    "    df.ExterCond = df.ExterCond.map(fivelevel_codes).astype(np.int64, copy=False)\n",
    "    df.HeatingQC = df.HeatingQC.map(fivelevel_codes).astype(np.int64, copy=False)\n",
    "    df.KitchenQual = df.KitchenQual.fillna(df.KitchenQual.mode()[0]).map(fivelevel_codes).astype(np.int64, copy=False)\n",
    "    df.Foundation = df.Foundation.map(foundation_codes).astype(np.int64, copy=False)\n",
    "    df.CentralAir = df.CentralAir.map(yno_codes).astype(np.int64, copy=False)\n",
    "    df.Electrical = df.Electrical.fillna(df['Electrical'].mode()[0]).map(electrical_codes).astype(np.int64, copy=False)\n",
    "    df.Functional = df.Functional.fillna(df['Functional'].mode()[0]).map(functional_codes).astype(np.int64, copy=False)\n",
    "    df.PavedDrive = df.PavedDrive.map(paveddrive_codes).astype(np.int64, copy=False)\n",
    "    df.SaleType = df.SaleType.fillna(df['SaleType'].mode()[0]).map(saletype_codes).astype(np.int64, copy=False)\n",
    "    df.SaleCondition = df.SaleCondition.map(salecondition_codes).astype(np.int64, copy=False)\n",
    "\n",
    "    df.BsmtFinSF1 = df.BsmtFinSF1.fillna(0)    \n",
    "    df.BsmtUnfSF = df.BsmtUnfSF.fillna(0)\n",
    "    df.TotalBsmtSF = df.TotalBsmtSF.fillna(0)    \n",
    "    df.TotalBath = df.TotalBath.fillna(0)\n",
    "    df.GarageCars = df.GarageCars.fillna(0)  \n",
    "    return df\n",
    "\n",
    "df_train = fill_and_map(df_train)\n",
    "df_test = fill_and_map(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train contains 44 columns, 1455 rows\nTest contains 43 columns, 1459 rows\n"
     ]
    }
   ],
   "source": [
    "print(f'Train contains {df_train.shape[1]} columns, {df_train.shape[0]} rows')\n",
    "print(f'Test contains {df_test.shape[1]} columns, {df_test.shape[0]} rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save datasets\n",
    "df_train.to_csv('train_normalized.csv', index=False, na_rep='NA')\n",
    "df_test.to_csv('test_normalized.csv', index=False, na_rep='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_table(data):\n",
    "    \"\"\"\n",
    "    A function which returns the number and percentage of null values in the given dataset.\n",
    "    \"\"\"\n",
    "    indices = data.isnull().sum().index\n",
    "    values = data.isnull().sum().values\n",
    "    percentages = []\n",
    "    for i in indices:\n",
    "        percentages.append((data[i].isnull().sum() / data[i].shape[0]) * 100)\n",
    "    d = {'Columns' : indices, 'Count of Null Values' : values, 'Approximate Percentage of Null Values' : percentages}\n",
    "    # data = dict(zip(indices, percentages))\n",
    "    null_frame = pd.DataFrame(data = d)\n",
    "    return null_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                Columns  Count of Null Values  \\\n",
       "11           HouseStyle                     0   \n",
       "12          OverallQual                     0   \n",
       "13          OverallCond                     0   \n",
       "14            YearBuilt                     0   \n",
       "15         YearRemodAdd                     0   \n",
       "16            ExterQual                     0   \n",
       "17            ExterCond                     0   \n",
       "18           Foundation                     0   \n",
       "10             BldgType                     0   \n",
       "42  MSSubclass_category                     0   \n",
       "\n",
       "    Approximate Percentage of Null Values  \n",
       "11                                    0.0  \n",
       "12                                    0.0  \n",
       "13                                    0.0  \n",
       "14                                    0.0  \n",
       "15                                    0.0  \n",
       "16                                    0.0  \n",
       "17                                    0.0  \n",
       "18                                    0.0  \n",
       "10                                    0.0  \n",
       "42                                    0.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Columns</th>\n      <th>Count of Null Values</th>\n      <th>Approximate Percentage of Null Values</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>11</td>\n      <td>HouseStyle</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>OverallQual</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>OverallCond</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>YearBuilt</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>YearRemodAdd</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>ExterQual</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>ExterCond</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>Foundation</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>BldgType</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>MSSubclass_category</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "source": [
    "null_frame_train = null_table(df_test)\n",
    "null_frame_train.sort_values(by = 'Approximate Percentage of Null Values').tail(10)"
   ]
  }
 ]
}